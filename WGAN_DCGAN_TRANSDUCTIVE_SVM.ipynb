{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN DCGAN TRANSDUCTIVE SVM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "iKabKqHqmEbS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deep Learning "
      ]
    },
    {
      "metadata": {
        "id": "OQ3sCQZLmMzB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Packages"
      ]
    },
    {
      "metadata": {
        "id": "-nq9wIEdmJdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.engine.topology import Layer\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Lambda, Input, Dense, Multiply, Add, Reshape, Flatten, Dropout, Activation, BatchNormalization, regularizers, Conv2D, MaxPooling2D\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from keras.layers.convolutional import Convolution2D, Conv2DTranspose, UpSampling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.layers.merge import _Merge\n",
        "import os, time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import pickle\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import imshow\n",
        "from keras.models import load_model\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ba8khrXY2Bf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Program Parameters"
      ]
    },
    {
      "metadata": {
        "id": "majaOQWMYz4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# seed \n",
        "np.random.seed(2018)\n",
        "tf.set_random_seed(2018)\n",
        "# save data to drive\n",
        "SAVE_RESULTS_TO_DRIVE = True\n",
        "FOLDER_ID = 'xxxxx'\n",
        "# ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5mWYE1MDMf5O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fashion Mnist Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "JN3EAUNB6jxR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def FM_pre_prossecing(is_vae=True):\n",
        "  \n",
        "  # download and get the data set\n",
        "  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "  if is_vae:\n",
        "    K.set_image_data_format('channels_first')\n",
        "    # image dimention\n",
        "    original_dim = 28*28\n",
        "    # reshape for the VAE\n",
        "    x_train = x_train.reshape(-1, original_dim) / 255.\n",
        "    x_test = x_test.reshape(-1, original_dim) / 255.\n",
        "    # categorical the y's\n",
        "#     y_train = np_utils.to_categorical(y_train, 10)\n",
        "#     y_test = np_utils.to_categorical(y_train, 10)\n",
        "  else:\n",
        "    K.set_image_data_format('channels_last')\n",
        "    # concatenate\n",
        "    X_train = np.concatenate((x_train, x_test), axis=0)\n",
        "    # reshape\n",
        "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
        "    x_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "  return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BeK4rnYl5Htj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Sample Data Evenly for SVM"
      ]
    },
    {
      "metadata": {
        "id": "kNDDsVgC5X9X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def balanced_subsample(x_data, y_data, subsample_size_per_label=100, is_random=False):\n",
        "  \n",
        "  # shuffle in random state\n",
        "  if is_random:\n",
        "    np.random.shuffle(x_data), np.random.shuffle(y_data)\n",
        "    \n",
        "  # return values\n",
        "  return_x, return_y = [], []\n",
        "  \n",
        "  dict_of_index =  {\"0\":[], \"1\":[], \"2\":[], \"3\":[], \"4\":[], \"5\":[], \"6\":[], \"7\":[], \"8\":[], \"9\":[]}\n",
        "  # try to add to the dict_of_index an element\n",
        "  for index, (xs, ys) in enumerate(zip(x_data, y_data)):\n",
        "    # extract y\n",
        "#     y_tag = [index for index, val in enumerate(ys) if val == 1][0]+1\n",
        "    # add new element\n",
        "#     if len(dict_of_index[str(y_tag)]) < subsample_size_per_label:\n",
        "    if len(dict_of_index[str(ys)]) < subsample_size_per_label:\n",
        "      # add index\n",
        "      dict_of_index[str(ys)].append(index)\n",
        "      \n",
        "  # return data\n",
        "  for key, value in dict_of_index.items():\n",
        "    for index in value:\n",
        "      #add x data\n",
        "      return_x.append(x_data[index])\n",
        "      # add y data\n",
        "      return_y.append(y_data[index])\n",
        "  \n",
        "  return np.array(return_x), np.array(return_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h9wJlCEDD3wa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Drive REST API"
      ]
    },
    {
      "metadata": {
        "id": "g4u7EIecD9LP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def set_drive_api():\n",
        "  # connect to drive\n",
        "  !pip install -U -q PyDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  from google.colab import files\n",
        "\n",
        "  # 1. Authenticate and create the PyDrive client.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  return drive\n",
        "\n",
        "  # PyDrive reference:\n",
        "  # https://gsuitedevs.github.io/PyDrive/docs/build/html/index.html\n",
        "  \n",
        "drive = set_drive_api()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1r-g-JiQA-tO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Save Model & Results to Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "Ouq4wyHZBKhi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_model_wigths_to_drive(my_model, saved_file_name):\n",
        "  # save weight locally on colab\n",
        "  my_model.save_weights(saved_file_name)\n",
        "  try:\n",
        "    # try to connect to drive\n",
        "    set_drive_api()\n",
        "    # save to drive\n",
        "    save(full_model_name)\n",
        "  except:\n",
        "    print(\"can't save exsiting model wigths to drive\")\n",
        "  \n",
        "def save(file_name):\n",
        "  # 2. Create & upload a file json file to drive\n",
        "  uploaded = drive.CreateFile({'title': file_name, \"parents\": [{\"kind\": \"drive#fileLink\",\"id\": FOLDER_ID}]})\n",
        "  uploaded.SetContentFile(file_name)\n",
        "  uploaded.Upload()\n",
        "  print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j1LTELAMBsfr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Upload Saved Results"
      ]
    },
    {
      "metadata": {
        "id": "pV_-QrQ9B0QK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_model_wigths_by_file_name(my_model, file_name, from_local_pc=False):\n",
        "  if not from_local_pc:\n",
        "    try:\n",
        "      # try to connect to drive\n",
        "      set_drive_api()\n",
        "      # try to download the file\n",
        "      restord_model_wigths_file_name = dowanload_file_drive_by_file_name(file_name)\n",
        "      # load the wigths\n",
        "      my_model.load_weights(restord_model_wigths_file_name)\n",
        "    except: \n",
        "      print(\"can't load exsiting model weights\")\n",
        "  else:\n",
        "    # remove  exsixting copies\n",
        "    try:\n",
        "      os.remove(file_name)\n",
        "    except: pass\n",
        "    # upload wights files from local file system\n",
        "    uploadedFiles = files.upload()\n",
        "    try:\n",
        "      my_model.load_weights(file_name)\n",
        "    except:\n",
        "      print(\"can't load exsiting model wigths\")\n",
        "  return my_model\n",
        "      \n",
        "def dowanload_file_drive_by_file_name(file_name):\n",
        "  # choose a local (colab) directory to store the data.\n",
        "  local_download_path = os.path.expanduser('~/data')\n",
        "  try:\n",
        "    os.makedirs(local_download_path)\n",
        "  except: pass\n",
        "  \n",
        "  # try to remove last file with the same name\n",
        "  try:\n",
        "    os.remove('/root/data/{}'.format(file_name))\n",
        "  except: pass\n",
        "  \n",
        "  file_list = drive.ListFile({'q': \"'\"+FOLDER_ID+\"' in parents\"}).GetList()\n",
        "  \n",
        "  for f in file_list:\n",
        "    # 3. Create & download by id.\n",
        "    if f['title'] == file_name:\n",
        "      print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "      fname = os.path.join(local_download_path, f['title'])\n",
        "      print('downloading to {}'.format(fname))\n",
        "      f_ = drive.CreateFile({'id': f['id']})\n",
        "      f_.GetContentFile(fname)\n",
        "      return fname"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mrDCu5eW_Xfb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Variational AutoEncoder"
      ]
    },
    {
      "metadata": {
        "id": "y8d2prWf_lFs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# adding Layer for KL Divergence\n",
        "class KLDivergenceLayer(Layer):\n",
        "\n",
        "    \"\"\" Identity transform layer that adds KL divergence to the final model loss.\"\"\"\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.is_placeholder = True\n",
        "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        mu, log_var = inputs\n",
        "\n",
        "        kl_batch = - .5 * K.sum(1 + log_var -K.square(mu) -K.exp(log_var), axis=-1)\n",
        "\n",
        "        self.add_loss(K.mean(kl_batch), inputs=inputs)\n",
        "\n",
        "        return inputs\n",
        "\n",
        "\n",
        "# VAE model\n",
        "class VAEModel:\n",
        "  \n",
        "  def __init__(self, original_dim = 784, intermediate_dim = 600, latent_dim = 50):\n",
        "    self.original_dim = original_dim\n",
        "    self.intermediate_dim = intermediate_dim\n",
        "    self.latent_dim = latent_dim\n",
        "    \n",
        "    # -- encoder --\n",
        "    x = Input((self.original_dim,))\n",
        "#     h_1 = Dense(self.intermediate_dim, activation='softplus')(x)\n",
        "    h_2 = Dense(self.intermediate_dim, activation='softplus')(x)\n",
        "   \n",
        "    # get mean and variance\n",
        "    z_mu = Dense(self.latent_dim)(h_2)\n",
        "    z_log_var = Dense(self.latent_dim)(h_2)\n",
        "    \n",
        "    # feeding the paramters to the new Layer\n",
        "    z_mu, z_log_var = KLDivergenceLayer()([z_mu, z_log_var])\n",
        "    z_sigma = Lambda(lambda t: K.exp(.5*t))(z_log_var)\n",
        "\n",
        "    # add the sampling to the model\n",
        "    eps = Input(tensor=K.random_normal(shape=(K.shape(x)[0], self.latent_dim)))\n",
        "    \n",
        "    # transformation to get z\n",
        "    z_eps = Multiply()([z_sigma, eps])\n",
        "    z = Add()([z_mu, z_eps])\n",
        "    \n",
        "    self.encoder = Model(x, z_mu)\n",
        "    \n",
        "    # -- decoder --\n",
        "    self.decoder = Sequential([\n",
        "    Dense(self.intermediate_dim, input_dim=self.latent_dim, activation='softplus'),\n",
        "#     Dense(self.intermediate_dim, activation='softplus'),\n",
        "    Dense(self.original_dim, activation='sigmoid')])\n",
        "    \n",
        "    # get the decoder results\n",
        "    x_pred = self.decoder(z)\n",
        "    \n",
        "    # end-to-end autoencoder build and complie the model\n",
        "    self.vae = Model(inputs=[x, eps], outputs=x_pred)\n",
        "    self.vae.compile(optimizer='rmsprop', loss=self.nll)\n",
        "    \n",
        "\n",
        "  def nll(self, y_true, y_pred):\n",
        "    \"\"\" Negative log likelihood (Bernoulli). \"\"\"\n",
        "\n",
        "    # keras.losses.binary_crossentropy gives the mean\n",
        "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
        "    \n",
        "  def get_vae_model(self):\n",
        "    return self.vae\n",
        "  \n",
        "  def get_encoder(self):\n",
        "    return self.encoder\n",
        "  \n",
        "  def get_decoder(self):\n",
        "    return self.decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5hv3t_qiS66O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train VAE"
      ]
    },
    {
      "metadata": {
        "id": "h4wlIPuZGq1-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_VAE(to_plot=True):\n",
        "  # get the model\n",
        "  vae = vae_class.get_vae_model()\n",
        "  # train the model\n",
        "  hist = vae.fit(x_train, x_train, shuffle=True, epochs=50, batch_size=128, validation_data=(x_test, x_test))\n",
        "  # plot loss graph\n",
        "  if to_plot:\n",
        "    ax = pd.DataFrame(hist.history).plot(title='Loss (NELBO) convergence',lw=2, colormap='jet', marker='.', markersize=10)\n",
        "    ax.set_xlabel(\"epochs\")\n",
        "    ax.set_ylabel(\"NELBO\")\n",
        "  # save the model\n",
        "  if SAVE_RESULTS_TO_DRIVE:\n",
        "    set_drive_api()\n",
        "    model_type = {\"VAE\":\"none\"}\n",
        "    save_model_to_drive(model_type, vae)\n",
        "    save_resluts_to_drive_as_txt(model_type, hist.history['loss'], hist.history['val_loss'])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "STTylX0FlMzU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Run VAE Training"
      ]
    },
    {
      "metadata": {
        "id": "jld53Aayjkz3",
        "colab_type": "code",
        "outputId": "136c96f8-ccd1-4ab5-e85a-069f2a9d4960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2236
        }
      },
      "cell_type": "code",
      "source": [
        "# build class model\n",
        "vae_class = VAEModel()\n",
        "# get the data\n",
        "(x_train, y_train), (x_test, y_test) = FM_pre_prossecing()\n",
        "# train the model\n",
        "train_VAE()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 3us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 303.4479 - val_loss: 281.6887\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 273.8211 - val_loss: 272.5722\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 265.1899 - val_loss: 262.7635\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 260.2535 - val_loss: 261.9590\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 256.7718 - val_loss: 256.2712\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 254.4683 - val_loss: 254.3220\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 252.8025 - val_loss: 255.5479\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 251.5547 - val_loss: 251.1141\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 250.5904 - val_loss: 251.7951\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 249.7642 - val_loss: 250.6585\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 249.0724 - val_loss: 249.6798\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 248.4990 - val_loss: 250.8171\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 247.9597 - val_loss: 250.5446\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 247.5177 - val_loss: 249.1234\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 247.0909 - val_loss: 249.3967\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 246.6853 - val_loss: 247.9719\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 246.3035 - val_loss: 247.7719\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 246.0071 - val_loss: 247.1128\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 245.6838 - val_loss: 248.2155\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 245.3805 - val_loss: 247.1719\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 245.1135 - val_loss: 247.2800\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 244.8682 - val_loss: 246.3854\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 244.6025 - val_loss: 246.6265\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 244.4100 - val_loss: 246.3883\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 244.2083 - val_loss: 246.3733\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 243.9655 - val_loss: 245.4023\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 243.7767 - val_loss: 246.7522\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 243.6254 - val_loss: 246.0992\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 243.4884 - val_loss: 245.7428\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 243.2781 - val_loss: 246.2325\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 243.1532 - val_loss: 246.0539\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 243.0003 - val_loss: 244.4809\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 242.8868 - val_loss: 244.8301\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 242.7408 - val_loss: 244.4804\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 242.6469 - val_loss: 244.5392\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 242.5099 - val_loss: 244.4075\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 242.3584 - val_loss: 245.3084\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 242.2449 - val_loss: 244.7049\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 242.1470 - val_loss: 244.8442\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 242.1064 - val_loss: 243.7494\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 241.9683 - val_loss: 243.9419\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 241.9031 - val_loss: 244.2654\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 241.7869 - val_loss: 243.8488\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 241.7515 - val_loss: 244.1107\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 241.6175 - val_loss: 243.8921\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 241.5931 - val_loss: 243.3315\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 241.4719 - val_loss: 243.8597\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 241.4285 - val_loss: 243.6878\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 241.3309 - val_loss: 243.9251\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 241.2670 - val_loss: 243.9409\n",
            "Uploaded file with ID 1Zxp1H4nFtCxP70fqiSaQBcr-kd36cQAP\n",
            "Saved full model VAE to disk\n",
            "Uploaded file with ID 1pYMaUhHApd6XG8K0n3TjKLaKFAEfHYTx\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEVCAYAAAACW4lMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0728fe8400>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "6nU78zgeD41z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Test VAE"
      ]
    },
    {
      "metadata": {
        "id": "E7Gulr7BD767",
        "colab_type": "code",
        "outputId": "fce97273-3028-4cd8-a394-c52e87e0fed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "model_filename = \"model_VAE.h5\"\n",
        "# download from drive and build the VAE model\n",
        "restord_file_name = dowanload_file_drive_by_file_name(model_filename)\n",
        "# crate the custom class\n",
        "restored_vae_model = VAEModel()\n",
        "# load the wights\n",
        "restored_vae_model.vae.load_weights(restord_file_name)\n",
        "# evaluate model loss on x_test\n",
        "restored_loss = restored_vae_model.vae.evaluate(x_test, x_test)\n",
        "print(\"restored VAE model loss on x_test: {}\".format(restored_loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: model_VAE.h5, id: 1Zxp1H4nFtCxP70fqiSaQBcr-kd36cQAP\n",
            "downloading to /root/data/model_VAE.h5\n",
            "10000/10000 [==============================] - 1s 68us/step\n",
            "restored VAE model loss on x_test: 243.82914182128906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IhZ5MKC__ohF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###TRANSDUCTIVE SVM"
      ]
    },
    {
      "metadata": {
        "id": "rGkn2YKDor2o",
        "colab_type": "code",
        "outputId": "7ae28025-fc0c-46d8-b2b1-039ab18d48f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "cell_type": "code",
      "source": [
        "# get the encoder\n",
        "encoder = vae_class.get_encoder()\n",
        "# create list for the results\n",
        "label_sizes = [100, 600, 1000, 3000]\n",
        "mean_accuracys = []\n",
        "mean_errors = []\n",
        "stds = []\n",
        "\n",
        "# set drive\n",
        "set_drive_api()\n",
        "# run on the diffrent label sizes\n",
        "for label_size in label_sizes:\n",
        "  # get the blanced data\n",
        "  x, y = balanced_subsample(x_train, y_train, subsample_size_per_label=label_size)\n",
        "  # use the encoder to generate the encode data\n",
        "  x_tag = encoder.predict(x)\n",
        "  # use simple svm classifer \n",
        "  clf = svm.SVC(gamma='scale')\n",
        "  # preform cross validation of 10 models\n",
        "  scores = cross_val_score(clf, x_tag, y, cv=10)\n",
        "  # cross validation copy the model and don't save it\n",
        "  # becuse of that we will run fit() again to save the fitted model, \n",
        "  # there might be differences between the results and the restored model\n",
        "  clf.fit(x_tag, y)\n",
        "  mean, std = np.mean(scores), np.std(scores)\n",
        "  error = 1-mean\n",
        "  # add results to list\n",
        "  mean_accuracys.append(mean)\n",
        "  mean_errors.append(error)\n",
        "  stds.append(std)\n",
        "  print(\"label size: {}, mean accuracy score: {}, std of accuracy: {}, mean error: {}.\".format(label_size, mean, std, error))\n",
        "  # save the model to disk\n",
        "  filename = 'svm_model_{}.sav'.format(label_size)\n",
        "  pickle.dump(clf, open(filename, 'wb'))\n",
        "  # upload to drive\n",
        "  save(filename)\n",
        "\n",
        "# summarize the results in the df and save it to drive\n",
        "model_results = \"svm_model_results.txt\"\n",
        "svm_results_df = pd.DataFrame({'label_size': label_sizes, 'mean_accuracy':mean_accuracys, 'mean_error':mean_errors, 'stds':stds})\n",
        "# write results locally\n",
        "svm_results_df.to_csv(model_results, header=None, index=None, sep=' ')\n",
        "# upload to drive\n",
        "save(model_results)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label size: 100, mean accuracy score: 0.8140000000000001, std of accuracy: 0.03903844259188627, mean error: 0.18599999999999994.\n",
            "Uploaded file with ID 16ZTBwwi7xUAPPSxhh-Hcl6lUFZO_rqnH\n",
            "label size: 600, mean accuracy score: 0.8470000000000001, std of accuracy: 0.013494854986664796, mean error: 0.1529999999999999.\n",
            "Uploaded file with ID 1Ce8PDjc-LCIhrZu_3CYSN6DvIWgfSkll\n",
            "label size: 1000, mean accuracy score: 0.8486, std of accuracy: 0.007657675887630665, mean error: 0.15139999999999998.\n",
            "Uploaded file with ID 1Ye5x7_gufAzrk5Iy33-HpGqbPiY0EljP\n",
            "label size: 3000, mean accuracy score: 0.8603333333333334, std of accuracy: 0.00408520365329428, mean error: 0.1396666666666666.\n",
            "Uploaded file with ID 1lTnYpscSAsniR7fVjDqD1fStsjn2EhHW\n",
            "Uploaded file with ID 1xw12DhVEVIQNiR-y2MrIskYAvNxoySwq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HefO3gs5DrbT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Test TRANSDUCTIVE SVM"
      ]
    },
    {
      "metadata": {
        "id": "vTnca3MmEAFo",
        "colab_type": "code",
        "outputId": "17dc5ed9-f270-44ec-8be3-c38808b1b110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "# load TRANSDUCTIVE SVM model according to your label size\n",
        "label_size = 1000\n",
        "filename = 'svm_model_{}.sav'.format(label_size)\n",
        "set_drive_api()\n",
        "\n",
        "# get the encoder from the model \n",
        "restored_encoder = restored_vae_model.get_encoder()\n",
        "# download model from drive to dick\n",
        "restord_file_name_svm = dowanload_file_drive_by_file_name(filename)\n",
        "# load the model from disk\n",
        "loaded_svm_model = pickle.load(open(restord_file_name_svm, 'rb'))\n",
        "\n",
        "x_for_test, y_of_test = balanced_subsample(x_train, y_train, subsample_size_per_label=label_size)\n",
        "# use the encoder to generate the encode data\n",
        "x_tag_x_for_test = restored_encoder.predict(x_for_test)\n",
        "# get the results from the the pretrained model\n",
        "result = loaded_svm_model.score(x_tag_x_for_test, y_of_test)\n",
        "print(\"Restored model results accuracy : {}, for number of labels: {}.\".format(result, label_size))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: svm_model_1000.sav, id: 1Ye5x7_gufAzrk5Iy33-HpGqbPiY0EljP\n",
            "downloading to /root/data/svm_model_1000.sav\n",
            "Restored model results accuracy : 0.8644, for number of labels: 1000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KaOB4vlv9zWm"
      },
      "cell_type": "markdown",
      "source": [
        "##WGAN"
      ]
    },
    {
      "metadata": {
        "id": "O5dwMPLZdC--",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "# The training ratio is the number of discriminator updates per generator update. The paper uses 5.\n",
        "TRAINING_RATIO = 5  \n",
        "GRADIENT_PENALTY_WEIGHT = 10  # As per the paper\n",
        "CLIP_VALUE = 0.01\n",
        "OPTIMIZER=Adam(0.0001, beta_1=0.5, beta_2=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yLPg-H5PnNRM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RandomWeightedAverage(_Merge):\n",
        "    \"\"\"Takes a randomly-weighted average of two tensors. In geometric terms, this outputs a random point on the line\n",
        "    between each pair of input points.\n",
        "    Inheriting from _Merge is a little messy but it was the quickest solution I could think of.\n",
        "    Improvements appreciated.\"\"\"\n",
        "\n",
        "    def _merge_function(self, inputs):\n",
        "        weights = K.random_uniform((BATCH_SIZE, 1, 1, 1))\n",
        "        return (weights * inputs[0]) + ((1 - weights) * inputs[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QaD6OVKzoAXN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_images(generator_model, number_of_images=10, is_wgan=True):\n",
        "    \"\"\"Feeds random seeds into the generator and tiles and saves the output to a PNG file.\"\"\"\n",
        "    test_image_stack = generator_model.predict(np.random.rand(number_of_images, 100))\n",
        "    test_image_stack = (test_image_stack * 127.5) + 127.5\n",
        "    test_image_stack = np.squeeze(np.round(test_image_stack).astype(np.uint8))\n",
        "    \n",
        "    image_list = [test_image_stack[i, :, :] for i in range(test_image_stack.shape[0])]\n",
        "    # ploting the image to screan\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for index, image_array in enumerate(image_list):\n",
        "      plt.subplot(10, 10, index+1)\n",
        "      # transform to image\n",
        "      im = Image.fromarray(image_array, mode='L')\n",
        "      # resize\n",
        "      im = im.resize((200, 200))\n",
        "      # show images\n",
        "      imshow(np.asarray(im))\n",
        "      plt.axis('off')\n",
        "      # get gan type\n",
        "      if is_wgan:\n",
        "        gan_type ='wgan'\n",
        "      else:\n",
        "        gan_type ='dcgan'\n",
        "      # save locally\n",
        "      file_name = '{}_img_{}.png'.format(gan_type, index)\n",
        "      im.save(file_name)\n",
        "      # try save to drive\n",
        "      try:\n",
        "        save(file_name)\n",
        "      except:\n",
        "        print(\"could not save to drive\")\n",
        "    # set up the images together nicely\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19NduKfGg59R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Wasserstein Loss"
      ]
    },
    {
      "metadata": {
        "id": "JgED2-vQdSlj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def wasserstein_loss(y_true, y_pred):\n",
        "    return K.mean(y_true * y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QQ9XsmoRg-cX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Gradient Penalty"
      ]
    },
    {
      "metadata": {
        "id": "BsRp1xvCedjU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gradient_penalty_loss(y_true, y_pred, averaged_samples, gradient_penalty_weight):\n",
        "    # first get the gradients:\n",
        "    #   assuming: - that y_pred has dimensions (batch_size, 1)\n",
        "    #             - averaged_samples has dimensions (batch_size, nbr_features)\n",
        "    # gradients afterwards has dimension (batch_size, nbr_features), basically\n",
        "    # a list of nbr_features-dimensional gradient vectors\n",
        "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
        "    # compute the euclidean norm by squaring ...\n",
        "    gradients_sqr = K.square(gradients)\n",
        "    #   ... summing over the rows ...\n",
        "    gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
        "    #   ... and sqrt\n",
        "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
        "    # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
        "    gradient_penalty = gradient_penalty_weight * K.square(1 - gradient_l2_norm)\n",
        "    # return the mean as loss over all the batch samples\n",
        "    return K.mean(gradient_penalty)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oGXP90KIngEA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###WGAN Generator"
      ]
    },
    {
      "metadata": {
        "id": "wat8D0SmmGMK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_wgan_generator():\n",
        "  \"\"\"Creates a generator model that takes a 100-dimensional noise vector as a \"seed\", \n",
        "  and outputs images of size 28x28x1.\"\"\"\n",
        "  model = Sequential()\n",
        "  model.add(Dense(1024))\n",
        "  model.add(LeakyReLU())\n",
        "  model.add(Dense(128 * 7 * 7))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU())\n",
        "  model.add(Reshape((7, 7, 128), input_shape=(128 * 7 * 7,)))\n",
        "  model.add(Conv2DTranspose(128, (5, 5), strides=2, padding='same'))\n",
        "  model.add(BatchNormalization(axis=3))\n",
        "  model.add(LeakyReLU())\n",
        "  model.add(Convolution2D(64, (5, 5), padding='same'))\n",
        "  model.add(BatchNormalization(axis=3))\n",
        "  model.add(LeakyReLU())\n",
        "  model.add(Conv2DTranspose(64, (5, 5), strides=2, padding='same'))\n",
        "  model.add(BatchNormalization(axis=3))\n",
        "  model.add(LeakyReLU())\n",
        "  # Because we normalized training inputs to lie in the range [-1, 1],\n",
        "  # the tanh function should be used for the output of the generator to ensure its output\n",
        "  # also lies in this range.\n",
        "  model.add(Convolution2D(1, (5, 5), padding='same', activation='tanh'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_o1yJKBgnoMH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### WGAN Discriminator"
      ]
    },
    {
      "metadata": {
        "id": "7aaXJOBymeVF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_wgan_discriminator():\n",
        "  \"\"\"Creates a discriminator model that takes an image as input and outputs a single value, representing whether\n",
        "  the input is real or generated.\"\"\"\n",
        "  model = Sequential()\n",
        "  model.add(Convolution2D(64, (5, 5), padding='same', input_shape=(28, 28, 1)))\n",
        "  model.add(LeakyReLU())\n",
        "  model.add(Convolution2D(128, (5, 5), kernel_initializer='he_normal', strides=[2, 2], data_format = 'channels_last'))\n",
        "  model.add(LeakyReLU())\n",
        "  model.add(Convolution2D(128, (5, 5), kernel_initializer='he_normal', padding='same', strides=[2, 2]))\n",
        "  model.add(LeakyReLU())\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, kernel_initializer='he_normal'))\n",
        "  model.add(LeakyReLU())\n",
        "  model.add(Dense(1, kernel_initializer='he_normal'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-7nHyNeXo_pG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup WGAN for Training"
      ]
    },
    {
      "metadata": {
        "id": "sj6K3q9CpCaU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class WGAN:\n",
        "  \n",
        "  def __init__(self):\n",
        "    \n",
        "    # get the data\n",
        "    (self.x_train, _), (_, _) = FM_pre_prossecing(False)\n",
        "\n",
        "    # initialize the generator and discriminator.\n",
        "    self.wgan_generator = build_wgan_generator()\n",
        "    self.wgan_discriminator = build_wgan_discriminator()\n",
        "\n",
        "    # The generator_model is used when we want to train the generator layers.\n",
        "    # As such, we ensure that the discriminator layers are not trainable.\n",
        "    for layer in self.wgan_discriminator.layers:\n",
        "        layer.trainable = False\n",
        "    self.wgan_discriminator.trainable = False\n",
        "\n",
        "    generator_input = Input(shape=(100,))\n",
        "    generator_layers = self.wgan_generator(generator_input)\n",
        "    discriminator_layers_for_generator = self.wgan_discriminator(generator_layers)\n",
        "    self.wgan_generator_model = Model(inputs=[generator_input], outputs=[discriminator_layers_for_generator])\n",
        "\n",
        "    # We use the Adam paramaters from Gulrajani et al.\n",
        "    self.wgan_generator_model.compile(optimizer=Adam(0.0001, beta_1=0.5, beta_2=0.9), loss=wasserstein_loss)\n",
        "\n",
        "    # Now that the generator_model is compiled, we can make the discriminator layers trainable.\n",
        "    for layer in self.wgan_discriminator.layers:\n",
        "        layer.trainable = True\n",
        "    for layer in self.wgan_generator.layers:\n",
        "        layer.trainable = False\n",
        "    self.wgan_discriminator.trainable = True\n",
        "    self.wgan_generator.trainable = False\n",
        "\n",
        "    # The discriminator_model is more complex. \n",
        "    # It takes both real image samples and random noise seeds as input.\n",
        "    # The noise seed is run through the generator model to get generated images. \n",
        "    # Both real and generated images\n",
        "    # are then run through the discriminator. \n",
        "    real_samples = Input(shape=x_train.shape[1:])\n",
        "    generator_input_for_discriminator = Input(shape=(100,))\n",
        "    generated_samples_for_discriminator = self.wgan_generator(generator_input_for_discriminator)\n",
        "    discriminator_output_from_generator = self.wgan_discriminator(generated_samples_for_discriminator)\n",
        "    discriminator_output_from_real_samples = self.wgan_discriminator(real_samples)\n",
        "\n",
        "    # We also need to generate weighted-averages of real and generated samples, to use for the gradient norm penalty.\n",
        "    averaged_samples = RandomWeightedAverage()([real_samples, generated_samples_for_discriminator])\n",
        "    # We then run these samples through the discriminator as well.\n",
        "    averaged_samples_out = self.wgan_discriminator(averaged_samples)\n",
        "\n",
        "    # keras limitations\n",
        "    partial_gp_loss = partial(gradient_penalty_loss,\n",
        "                              averaged_samples=averaged_samples,\n",
        "                              gradient_penalty_weight=GRADIENT_PENALTY_WEIGHT)\n",
        "    partial_gp_loss.__name__ = 'gradient_penalty'  \n",
        "\n",
        "\n",
        "    self.wgan_discriminator_model = Model(inputs=[real_samples, generator_input_for_discriminator],\n",
        "                                outputs=[discriminator_output_from_real_samples, discriminator_output_from_generator, averaged_samples_out])\n",
        "\n",
        "    # We use the Wasserstein loss for both the real and generated samples,\n",
        "    # and the gradient penalty loss for the averaged samples.\n",
        "    self.wgan_discriminator_model.compile(optimizer=Adam(0.0001, beta_1=0.5, beta_2=0.9),\n",
        "                                loss=[wasserstein_loss, wasserstein_loss, partial_gp_loss])\n",
        "\n",
        "    # We make three label vectors for training. positive_y is the label vector for real samples, with value 1.\n",
        "    # negative_y is the label vector for generated samples, with value -1. The dummy_y vector is passed to the\n",
        "    # gradient_penalty loss function and is not used.\n",
        "    self.positive_y = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n",
        "    self.negative_y = -positive_y\n",
        "    self.dummy_y = np.zeros((BATCH_SIZE, 1), dtype=np.float32)\n",
        "    \n",
        "  def train_WGAN(self, number_of_epochs, save_results=True, generate_new_images=True, load_exsiting_model=True, plot_loss=True, use_clip_weights=False):\n",
        "\n",
        "    # file names\n",
        "    wgan_discriminator_model_wigths_file_name = 'wgan_discriminator_model_wigths.h5'\n",
        "    wgan_generator_model_wigths_file_name = 'wgan_generator_model_wigths.h5'\n",
        "    wgan_generator_file_name = 'wgan_generator_wigths.hdf5'\n",
        "\n",
        "    if load_exsiting_model:\n",
        "      self.wgan_discriminator_model = load_model_wigths_by_file_name(self.wgan_discriminator_model, wgan_discriminator_model_wigths_file_name)\n",
        "      self.wgan_generator_model = load_model_wigths_by_file_name(self.wgan_generator_model, wgan_generator_model_wigths_file_name)\n",
        "#       self.wgan_generator = load_model_wigths_by_file_name(self.wgan_generator, wgan_generator_wigths_file_name)\n",
        "\n",
        "    # shuffel the data\n",
        "    np.random.shuffle(self.x_train)\n",
        "\n",
        "    # masure total training time\n",
        "    t0 = time.time()\n",
        "\n",
        "    # end of epoch lists\n",
        "    self.wgan_discriminator_end_of_epoch_loss = []\n",
        "    self.wgan_generator_loss = []\n",
        "    \n",
        "    for epoch in range(number_of_epochs):\n",
        "\n",
        "      # masure epoch training time\n",
        "      t2 = time.time()\n",
        "\n",
        "      # ---------------------\n",
        "      #  Train Discriminator\n",
        "      # ---------------------\n",
        "\n",
        "      print(\"Epoch: \", epoch)\n",
        "      print(\"Number of batches: \", int(self.x_train.shape[0] // BATCH_SIZE))\n",
        "\n",
        "      self.wgan_discriminator_loss = []\n",
        "      \n",
        "      minibatches_size = BATCH_SIZE * TRAINING_RATIO\n",
        "\n",
        "      for i in range(int(self.x_train.shape[0] // (BATCH_SIZE * TRAINING_RATIO))):\n",
        "        discriminator_minibatches = self.x_train[i * minibatches_size:(i + 1) * minibatches_size]\n",
        "\n",
        "        for j in range(TRAINING_RATIO):\n",
        "          image_batch = discriminator_minibatches[j * BATCH_SIZE:(j + 1) * BATCH_SIZE]\n",
        "          noise = np.random.rand(BATCH_SIZE, 100).astype(np.float32)\n",
        "          self.wgan_discriminator_loss.append(self.wgan_discriminator_model.train_on_batch([image_batch, noise], \n",
        "                                                                                           [self.positive_y, self.negative_y, self.dummy_y]))\n",
        "      # add last loss to the list\n",
        "      self.wgan_discriminator_end_of_epoch_loss.append(self.wgan_discriminator_loss[-1][0])\n",
        "      \n",
        "      if use_clip_weights:\n",
        "        # Clip discriminator weights\n",
        "        for l in self.wgan_discriminator_model.layers:\n",
        "            weights = l.get_weights()\n",
        "            weights = [np.clip(w, -CLIP_VALUE, CLIP_VALUE) for w in weights]\n",
        "            l.set_weights(weights)\n",
        "\n",
        "      # ---------------------\n",
        "      #  Train Generator\n",
        "      # ---------------------\n",
        "\n",
        "      self.wgan_generator_loss.append(self.wgan_generator_model.train_on_batch(np.random.rand(BATCH_SIZE, 100), self.positive_y))\n",
        "\n",
        "      t3 = time.time()\n",
        "      print(\"Epoch training time: %0.2fs\" % (t3 - t2))\n",
        "\n",
        "    t1 = time.time()\n",
        "    print(\"Total training time: %0.2fs\" % (t1 - t0))\n",
        "    \n",
        "    # summarize the results in the df    \n",
        "    wgan_results_df = pd.DataFrame({\"generator_loss\": self.wgan_generator_loss, \"discriminator_loss\":self.wgan_discriminator_end_of_epoch_loss})\n",
        "\n",
        "    if save_results:\n",
        "\n",
        "      # save wights locally \n",
        "      # -- for retrain --\n",
        "      self.wgan_discriminator_model.save_weights(wgan_discriminator_model_wigths_file_name)\n",
        "      self.wgan_generator_model.save_weights(wgan_generator_model_wigths_file_name)\n",
        "      # -- for generation of new images -- \n",
        "      self.wgan_generator.save(wgan_generator_file_name)\n",
        "\n",
        "      # upload to drive\n",
        "      set_drive_api()\n",
        "      save(wgan_discriminator_model_wigths_file_name)\n",
        "      save(wgan_generator_model_wigths_file_name)\n",
        "      save(wgan_generator_file_name)\n",
        "\n",
        "      # write results locally\n",
        "      model_results = \"wgan_model_results.txt\"\n",
        "      wgan_results_df.to_csv(model_results, header=None, index=None, sep=' ')\n",
        "      # upload to drive\n",
        "      save(model_results)\n",
        "\n",
        "    if plot_loss:\n",
        "      ax = wgan_results_df.plot(title='Loss Per Epochs',lw=2, colormap='jet', marker='.', markersize=10)\n",
        "      ax.set_xlabel(\"Epochs\")\n",
        "      ax.set_ylabel(\"Loss\")  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SWnsEU9xJ91h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Train WGAN"
      ]
    },
    {
      "metadata": {
        "id": "YB-VzzU5_eEc",
        "colab_type": "code",
        "outputId": "a00b7827-fe74-4fdb-aea2-e66e5455d521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "cell_type": "code",
      "source": [
        "# set up wgan instance\n",
        "wgan = WGAN()\n",
        "# train it\n",
        "wgan.train_WGAN(2, plot_loss=False, load_exsiting_model=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: wgan_discriminator_model_wigths.h5, id: 1uTf11euZ5WaJpUC5xeO_gGPnQTLOQU8c\n",
            "downloading to /root/data/wgan_discriminator_model_wigths.h5\n",
            "title: wgan_generator_model_wigths.h5, id: 1aUviWuzH71Qhh6KCw2JgZDDwDKY3-wyJ\n",
            "downloading to /root/data/wgan_generator_model_wigths.h5\n",
            "Epoch:  0\n",
            "Number of batches:  1093\n",
            "Epoch training time: 116.99s\n",
            "Epoch:  1\n",
            "Number of batches:  1093\n",
            "Epoch training time: 98.19s\n",
            "Total training time: 215.18s\n",
            "Uploaded file with ID 1YpyPoXraU5NgoXTfaZRYb7v5-R4lCAcf\n",
            "Uploaded file with ID 1WZgwAk8CR4-QwBrwNOAJLumXqF0_x1Va\n",
            "Uploaded file with ID 1Ry9UPSyW9BwlzBRppbW2oEp_AFL2ufal\n",
            "Uploaded file with ID 19TxvAsu_fTBHulaRKdVAtgSfDVUhkFfi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JzVO6urNqM9M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### WGAN Genarate New Images From Loaded Model"
      ]
    },
    {
      "metadata": {
        "id": "kWALZYbeq7qF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# setup number of images and run the generator\n",
        "# use more then 1\n",
        "number_of_images = 10\n",
        "# wgan_generator_wigths_file_name = 'wgan_generator_wigths.h5'\n",
        "wgan_generator_file_name = 'wgan_generator_wigths.hdf5'\n",
        "is_from_pc = False\n",
        "run_file_name = ''\n",
        "\n",
        "if not is_from_pc:\n",
        "  # download the file from drive\n",
        "  run_file_name = dowanload_file_drive_by_file_name(wgan_generator_file_name)\n",
        "else:\n",
        "  # upload model file from local file system\n",
        "  uploadedFiles = files.upload()\n",
        "  run_file_name = wgan_generator_file_name\n",
        "\n",
        "# load the model\n",
        "wgan_generator = load_model(run_file_name)\n",
        "# generate images\n",
        "generate_images(model, number_of_images, is_wgan=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2LTiK-uz9NSm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DCGAN"
      ]
    },
    {
      "metadata": {
        "id": "P3mPvhfuez1h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###DCGAN Generator"
      ]
    },
    {
      "metadata": {
        "id": "ydHWF1XZ97ng",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_dc_generator():\n",
        "  generator = Sequential([\n",
        "          Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2)),\n",
        "          BatchNormalization(),\n",
        "          Reshape((7,7,128)),\n",
        "          UpSampling2D(),\n",
        "          Convolution2D(64, 5, 5, border_mode='same', activation=LeakyReLU(0.2)),\n",
        "          BatchNormalization(),\n",
        "          UpSampling2D(),\n",
        "          Convolution2D(1, 5, 5, border_mode='same', activation='tanh')\n",
        "      ])\n",
        "  generator.compile(loss='binary_crossentropy', optimizer=Adam())\n",
        "  return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VD8aPOPffBdh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###DCGAN Discriminator "
      ]
    },
    {
      "metadata": {
        "id": "I9EP5xZTfHQd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_dc_discriminator():\n",
        "  discriminator = Sequential([\n",
        "          Convolution2D(64, 5, 5, subsample=(2,2), input_shape=(28,28,1), border_mode='same', activation=LeakyReLU(0.2)),\n",
        "          Dropout(0.3),\n",
        "          Convolution2D(128, 5, 5, subsample=(2,2), border_mode='same', activation=LeakyReLU(0.2)),\n",
        "          Dropout(0.3),\n",
        "          Flatten(),\n",
        "          Dense(1, activation='sigmoid')\n",
        "      ])\n",
        "  discriminator.compile(loss='binary_crossentropy', optimizer=Adam())\n",
        "  return discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dGRDbQ8bj9fO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup DCGAN"
      ]
    },
    {
      "metadata": {
        "id": "9QkafE8MkARt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DCGAN:\n",
        "  \n",
        "  def __init__(self):\n",
        "\n",
        "    # get the data\n",
        "    (self.x_train, _), (_, _) = FM_pre_prossecing(False)\n",
        "    # get generator and discriminator\n",
        "    self.dcgan_discriminator = build_dc_discriminator()\n",
        "    self.dcgan_generator = build_dc_generator()\n",
        "\n",
        "    self.dcgan_discriminator.trainable = False\n",
        "    ganInput = Input(shape=(100,))\n",
        "    # getting the output of the generator\n",
        "    # and then feeding it to the discriminator\n",
        "    # new model = D(G(input))\n",
        "    x = self.dcgan_generator(ganInput)\n",
        "    ganOutput = self.dcgan_discriminator(x)\n",
        "    self.dcgan = Model(input=ganInput, output=ganOutput)\n",
        "    self.dcgan.compile(loss='binary_crossentropy', optimizer=Adam())\n",
        "    \n",
        "  def train_DCGAN(self, number_of_epochs, save_results=True, generate_new_images=True, load_exsiting_model=True, plot_loss=True):\n",
        "\n",
        "    # file names\n",
        "    dcgan_discriminator_model_wigths_file_name = 'dcgan_discriminator_model_wigths.h5'\n",
        "    dcgan_generator_model_wigths_file_name = 'dcgan_generator_model_wigths.h5'\n",
        "    \n",
        "    if load_exsiting_model:\n",
        "      self.dcgan_discriminator = load_model_wigths_by_file_name(self.dcgan_discriminator, dcgan_discriminator_model_wigths_file_name)\n",
        "      self.dcgan_generator = load_model_wigths_by_file_name(self.dcgan_generator, dcgan_generator_model_wigths_file_name)\n",
        "\n",
        "    batch_size=128\n",
        "    batch_count = self.x_train.shape[0] // batch_size\n",
        "    self.dcgan_discriminator_end_of_epoch_loss = []\n",
        "    self.dcgan_generator_end_of_epoch_loss = []\n",
        "    \n",
        "    \n",
        "    # shuffel the data\n",
        "    np.random.shuffle(self.x_train)\n",
        "\n",
        "    # masure total training time\n",
        "    t0 = time.time()\n",
        "\n",
        "    for epoch in range(number_of_epochs):\n",
        "\n",
        "      # masure epoch training time\n",
        "      t2 = time.time()\n",
        "\n",
        "      # ---------------------\n",
        "      #  Train Discriminator\n",
        "      # ---------------------\n",
        "\n",
        "      print(\"Epoch: \", epoch)\n",
        "      \n",
        "      dc_discriminator_loss = []\n",
        "      dc_generator_loss = []\n",
        "      \n",
        "      for j in range(batch_count):\n",
        "        # Input for the generator\n",
        "        noise_input = np.random.rand(batch_size, 100)\n",
        "\n",
        "        # getting random images from x_train of size=batch_size \n",
        "        # these are the real images that will be fed to the discriminator\n",
        "        image_batch = self.x_train[np.random.randint(0, self.x_train.shape[0], size=batch_size)]\n",
        "\n",
        "        # these are the predicted images from the generator\n",
        "        predictions = self.dcgan_generator.predict(noise_input, batch_size=batch_size)\n",
        "\n",
        "        # the discriminator takes in the real images and the generated images\n",
        "        X = np.concatenate([predictions, image_batch])\n",
        "\n",
        "        # labels for the discriminator\n",
        "        y_discriminator = [0]*batch_size + [1]*batch_size\n",
        "\n",
        "        # Let's train the discriminator\n",
        "        self.dcgan_discriminator.trainable = True\n",
        "        dc_discriminator_loss.append(self.dcgan_discriminator.train_on_batch(X, y_discriminator))\n",
        "\n",
        "        # Let's train the generator\n",
        "        noise_input = np.random.rand(batch_size, 100)\n",
        "        y_generator = [1]*batch_size\n",
        "        \n",
        "        # ---------------------\n",
        "        #  Train Generator\n",
        "        # ---------------------\n",
        "        \n",
        "        self.dcgan_discriminator.trainable = False\n",
        "        dc_generator_loss.append(self.dcgan.train_on_batch(noise_input, y_generator))\n",
        "\n",
        "      t3 = time.time()\n",
        "      print(\"Epoch training time: %0.2fs\" % (t3 - t2))\n",
        "  #     print(\"Discriminator metrics names: {}\".format(discriminator_model.metrics_names))\n",
        "      print(\"Generator loss: {}, Discriminator loss: {}\".format(1 - dc_generator_loss[-1], 1 - dc_discriminator_loss[-1]))\n",
        "      # add end of epoch losses\n",
        "      self.dcgan_discriminator_end_of_epoch_loss.append(1 - dc_discriminator_loss[-1])\n",
        "      self.dcgan_generator_end_of_epoch_loss.append(1 - dc_generator_loss[-1])\n",
        "\n",
        "  #     if generate_new_images and epoch % 10 == 0 :\n",
        "  #       generate_images(dc_generator, is_wgan=False)\n",
        "\n",
        "    t1 = time.time()\n",
        "    print(\"Total training time: %0.2fs\" % (t1 - t0))\n",
        "\n",
        "    # summarize the results in the df    \n",
        "    dcgan_results_df = pd.DataFrame({\"generator_end_of_epoch_loss\": self.dcgan_generator_end_of_epoch_loss, \n",
        "                                     \"discriminator_end_of_epoch_loss\":self.dcgan_discriminator_end_of_epoch_loss})\n",
        "    if save_results:\n",
        "      # save wights locally \n",
        "      self.dcgan_discriminator.save_weights(dcgan_discriminator_model_wigths_file_name)\n",
        "      self.dcgan_generator.save_weights(dcgan_generator_model_wigths_file_name)\n",
        "\n",
        "      set_drive_api()\n",
        "      # upload to drive\n",
        "      save(dcgan_discriminator_model_wigths_file_name)\n",
        "      save(dcgan_generator_model_wigths_file_name)\n",
        "\n",
        "      # write results locally\n",
        "      model_results = \"dcgan_model_results.txt\"\n",
        "      dcgan_results_df.to_csv(model_results, header=None, index=None, sep=' ')\n",
        "      # upload to drive\n",
        "      save(model_results)\n",
        "\n",
        "    if plot_loss:\n",
        "      ax = dcgan_results_df.plot(title='Loss Per Epochs',lw=2, colormap='jet', marker='.', markersize=10)\n",
        "      ax.set_xlabel(\"Epochs\")\n",
        "      ax.set_ylabel(\"Loss\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1WaO0BVRlotk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train DCGAN"
      ]
    },
    {
      "metadata": {
        "id": "rVT82pQ-2bBt",
        "colab_type": "code",
        "outputId": "a34660aa-c9ba-4249-e14d-6d80620b27a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "cell_type": "code",
      "source": [
        "# set up wgan instance\n",
        "dcgan = DCGAN()\n",
        "# train it\n",
        "dcgan.train_DCGAN(5, generate_new_images=False, load_exsiting_model=True, plot_loss=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: dcgan_discriminator_model_wigths.h5, id: 1G3qmrH0XVRRoVeRf9ltVNz8Zlaz3aaxh\n",
            "downloading to /root/data/dcgan_discriminator_model_wigths.h5\n",
            "title: dcgan_generator_model_wigths.h5, id: 106Ame5j1uAuvo_ZMTx3y6rulCWdMt7R9\n",
            "downloading to /root/data/dcgan_generator_model_wigths.h5\n",
            "Epoch:  0\n",
            "Epoch training time: 54.34s\n",
            "Generator loss: -4.210963249206543, Discriminator loss: 0.8747262060642242\n",
            "Epoch:  1\n",
            "Epoch training time: 41.60s\n",
            "Generator loss: -4.053496360778809, Discriminator loss: 0.9240037649869919\n",
            "Epoch:  2\n",
            "Epoch training time: 41.41s\n",
            "Generator loss: -7.973957061767578, Discriminator loss: 0.8359526097774506\n",
            "Epoch:  3\n",
            "Epoch training time: 41.51s\n",
            "Generator loss: -2.5970640182495117, Discriminator loss: 0.8567473441362381\n",
            "Epoch:  4\n",
            "Epoch training time: 41.38s\n",
            "Generator loss: -7.028169631958008, Discriminator loss: 0.9402674846351147\n",
            "Total training time: 220.25s\n",
            "Uploaded file with ID 1xRRzuh6zmjG6CUq2FmPQW7oxjMAeEzjU\n",
            "Uploaded file with ID 1XaAcOJWx4DjWjrCrAT_rK_Fk3J8ILrlP\n",
            "Uploaded file with ID 1oYB86fioTaEGliC0EV4mKcZHxXFz-PNn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7MWnXQbAfrNt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Genarate New Images From Exsicting DCGAN Model "
      ]
    },
    {
      "metadata": {
        "id": "Q760-F4I_UY9",
        "colab_type": "code",
        "outputId": "8027cbd9-958a-4a0c-979a-c89a94291cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "number_of_images = 10\n",
        "file_name = 'dcgan_generator_model_wigths.h5'\n",
        "is_from_pc = False\n",
        "# create untrained dcgan generator \n",
        "empty_dcgan_generator = build_dc_generator()\n",
        "# load wigths on the generator\n",
        "new_dcgan_generator = load_model_wigths_by_file_name(empty_dcgan_generator, file_name, from_local_pc=is_from_pc)\n",
        "# generate the number of images needed\n",
        "generate_images(new_dcgan_generator, number_of_images, is_wgan=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: dcgan_generator_model_wigths.h5, id: 1XaAcOJWx4DjWjrCrAT_rK_Fk3J8ILrlP\n",
            "downloading to /root/data/dcgan_generator_model_wigths.h5\n",
            "Uploaded file with ID 1tn5KjmW8Vm9ml2ez_uYK11aI_GpqIMk1\n",
            "Uploaded file with ID 19a4-KquzbUbOpkipgeAxKNAoYeoqPJa0\n",
            "Uploaded file with ID 1cqcfuG81bYLOW0ubwP1tX3gv4l1GhCIA\n",
            "Uploaded file with ID 1jSeiOumqUewQ3b3P9fK3FMWVYwd-QAoR\n",
            "Uploaded file with ID 1ns4dxnZBinjDJ_s_O34VAIvQZIetk5MY\n",
            "Uploaded file with ID 1mKgi7zBATt26d-9EgX5gK8vRR0uKdGdm\n",
            "Uploaded file with ID 1wUzmfoNG-L2L2HmhI2stc47rElI94_aw\n",
            "Uploaded file with ID 1MC3M2MCVYze6We9xwUoxHhU08sEQQOa9\n",
            "Uploaded file with ID 1i2PObUwddrJxsiPyF5eaZmoGPu5Ikad-\n",
            "Uploaded file with ID 1qleJZKy_EV_M-R5gLU_xSAJ2ZDH3NY97\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAABACAYAAADoFerUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f45084c8d68>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}